{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fundamental-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model_checkpoint = 'cointegrated/rubert-base-cased-nli-twoway'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "def predict_pair(text1, text2):\n",
    "    with torch.inference_mode():\n",
    "        out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n",
    "        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n",
    "        return {v: proba[k] for k, v in model.config.id2label.items()}['entailment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "executive-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "voluntary-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = [l.strip().split('\\t') for l in open(f\"data/raw/zipped/news.tsv\") if len(l.split('\\t')) == 2]\n",
    "backed = [l.strip().split('\\t') for l in open(f\"data/raw/zipped/pairs450.tsv\") if len(l.split('\\t')) == 2]\n",
    "subs = [l.strip().split('\\t') for l in open(f\"data/raw/zipped/subtitles.tsv\") if len(l.split('\\t')) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "italic-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter([len(l) for l in subs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "native-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"news\": news,\n",
    "        \"backed\": backed,\n",
    "        \"subs\": subs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "satisfactory-costs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 88350/2337604 [14:23<6:06:03, 102.41it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 12%|█▏        | 288521/2337604 [47:08<5:33:32, 102.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 21%|██        | 493230/2337604 [1:20:54<5:01:08, 102.08it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 82%|████████▏ | 1928494/2337604 [5:16:03<1:09:06, 98.67it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 91%|█████████▏| 2135391/2337604 [5:50:09<32:59, 102.16it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████▉| 2336997/2337604 [6:23:09<00:06, 101.01it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 189752/445138 [33:33<44:03, 96.61it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 84%|████████▍ | 373408/445138 [1:06:03<12:29, 95.75it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 40%|████      | 126872/315655 [20:27<30:43, 102.40it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 315655/315655 [50:49<00:00, 103.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "with open('data/rysshe_entailment.tsv', 'w', encoding='utf8') as f:\n",
    "    for k in data:\n",
    "        for text1, text2 in tqdm.tqdm(data[k]):\n",
    "            ent1 = str(float(predict_pair(text1, text2)))\n",
    "            ent2 = str(float(predict_pair(text2, text1)))\n",
    "            f.write('\\t'.join([k, text1, text2, ent1, ent2])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "auburn-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [l.split('\\t') for l in open('data/rysshe_entailment.tsv').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "animal-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df = pd.DataFrame(df, columns=['kind', 'text1', 'text2', 'ent1', 'ent2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "expensive-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ent1'] = df['ent1'].astype(float)\n",
    "df['ent2'] = df['ent2'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "valuable-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/rysshe_entailment.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuck-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/rysshe_entailment.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "biblical-steam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ğ�Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Ğ�Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "modern-firewall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'самолеты работники'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'самолеты работники'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resistant-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.ent1 > 0.7) & (df.ent2 > 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brown-burst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approximate-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.text1.str.lower().str.contains('чёрт|черт|бля|хрен|целк|хер|чё |че') | df.text2.str.lower().str.contains('чёрт|черт|бля|хрен|целк|хер|чё |че'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "provincial-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.text1.str.len() + df.text2.str.len()) > 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "engaged-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.text1.str.split().apply(len) > 3) & (df.text2.str.split().apply(len) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "latin-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.text1.apply(lambda x: '...' in x)) | (df.text2.apply(lambda x: '...' in x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "political-blond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300817"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "practical-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vity(row):\n",
    "    if 'вы' in row['text1'].lower() and 'ты' in row['text2'].lower():\n",
    "        return True\n",
    "    elif 'вы' in row['text2'].lower() and 'ты' in row['text1'].lower():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "explicit-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.apply(vity, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "square-kitchen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphabet_detector import AlphabetDetector\n",
    "ad = AlphabetDetector()\n",
    "\n",
    "\n",
    "df = df[~(df.text1.apply(lambda x: ad.is_latin(x)))]\n",
    "df = df[~(df.text2.apply(lambda x: ad.is_latin(x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "desirable-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "behavioral-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['leven'] = df.apply(lambda x: similar(x['text1'], x['text2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "focal-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['leven'] < 0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pressed-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "sw = ('ну', 'хуй', 'хуя', 'ээ', 'эээ', 'мэм',\n",
    "      'ох', 'ах', 'вау', 'бог', 'боже', 'эй', '...', '—', 'дерьмо')\n",
    "def stopwords(s):\n",
    "    for tok in tokenize(s):\n",
    "        if tok.text.lower() in sw:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def repeat(s):\n",
    "    toks = [_.text for _ in tokenize(s)]\n",
    "    if len(toks) / len(set(toks)) > 2:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "alone-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text1.apply(stopwords)]\n",
    "df = df[~df.text2.apply(stopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "united-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text1.apply(repeat)]\n",
    "df = df[~df.text2.apply(repeat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "union-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text1.apply(lambda x: 'хер' in x)]\n",
    "df = df[~df.text2.apply(lambda x: 'хер' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "amazing-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "from collections import Counter\n",
    "from razdel import tokenize\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "\n",
    "def match_ents(s1, s2):\n",
    "    doc1, doc2 = Doc(s1), Doc(s2)\n",
    "    \n",
    "    doc1.segment(segmenter)\n",
    "    doc2.segment(segmenter)\n",
    "    \n",
    "    doc1.tag_ner(ner_tagger)\n",
    "    doc2.tag_ner(ner_tagger)\n",
    "    print(doc1.spans, doc2.spans)\n",
    "    if Counter([s.type for s in doc1.spans]) != Counter([s.type for s in doc2.spans]):\n",
    "        return False\n",
    "    \n",
    "    numbers1 = set()\n",
    "    numbers2 = set()\n",
    "    \n",
    "    for tok in doc1.tokens:\n",
    "        if has_numbers(tok.text):\n",
    "            numbers1.add(tok.text)\n",
    "    \n",
    "    for tok in doc2.tokens:\n",
    "        if has_numbers(tok.text):\n",
    "            numbers2.add(tok.text)\n",
    "    \n",
    "    if numbers1 != numbers2:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "    \n",
    "\n",
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def match_abbr(s1, s2):\n",
    "    abbrs1 = set()\n",
    "    abbrs2 = set()\n",
    "    \n",
    "    for tok in tokenize(s1):\n",
    "        if tok.text.isupper() and len(tok.text) > 1:\n",
    "            abbrs1.add(tok.text)\n",
    "    for tok in tokenize(s2):\n",
    "        if tok.text.isupper() and len(tok.text) > 1:\n",
    "            abbrs2.add(tok.text)\n",
    "    if abbrs1 == abbrs2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def match_latin(s1, s2):\n",
    "    lat1 = set()\n",
    "    lat2 = set()\n",
    "    \n",
    "    for tok in tokenize(s1):\n",
    "        if ad.is_latin(tok.text) and tok.text.isalpha():\n",
    "            lat1.add(tok.text)\n",
    "    for tok in tokenize(s2):\n",
    "        if ad.is_latin(tok.text) and tok.text.isalpha():\n",
    "            lat2.add(tok.text)\n",
    "\n",
    "    if lat1 == lat2:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "postal-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.apply(lambda x: match_abbr(x['text1'], x['text2']), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "efficient-picking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221801"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "still-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221801/221801 [10:46<00:00, 343.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "ner_data = []\n",
    "for i, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    if match_ents(row['text1'], row['text2']):\n",
    "        ner_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "invisible-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.index.isin(ner_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "geographic-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "mathematical-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_gender(s1, s2):\n",
    "    try:\n",
    "        g = set()\n",
    "        d1 = Doc(s1)\n",
    "        d1.segment(segmenter)\n",
    "        d1.parse_syntax(syntax_parser)\n",
    "        d1.tag_morph(morph_tagger)\n",
    "\n",
    "        d2 = Doc(s2)\n",
    "        d2.segment(segmenter)\n",
    "        d2.parse_syntax(syntax_parser)\n",
    "        d2.tag_morph(morph_tagger)\n",
    "\n",
    "        root_g1 = g.add([_.feats['Gender'] for _ in d1.tokens if _.rel =='root'][0])\n",
    "        root_g2 = g.add([_.feats['Gender'] for _ in d2.tokens if _.rel =='root'][0])\n",
    "    #     print(g)\n",
    "        if g == {'Fem', 'Masc'}:\n",
    "            return False\n",
    "    except:\n",
    "        pass\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "square-mentor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189680/189680 [15:21<00:00, 205.82it/s]\n"
     ]
    }
   ],
   "source": [
    "gen_data = []\n",
    "\n",
    "for i, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    if root_gender(row['text1'], row['text2']):\n",
    "        gen_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "occupied-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.index.isin(gen_data) & (df.kind=='subs')) | (df.kind!='subs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "owned-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.apply(lambda x: match_latin(x['text1'], x['text2']), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "arctic-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text1.apply(lambda x: 'блин' in x)]\n",
    "df = df[~df.text2.apply(lambda x: 'блин' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "false-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text1.apply(lambda x: ('че ' in x.lower()) or ('чё ' in x.lower()))]\n",
    "df = df[~df.text2.apply(lambda x: ('че ' in x.lower()) or ('чё 'in x.lower()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "north-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kind                                                  news\n",
       "text1    Дочь Стивена Спилберга решила сделать карьеру ...\n",
       "text2           Дочь Стивена Спилберга стала порноактрисой\n",
       "ent1                                              0.982754\n",
       "ent2                                              0.959038\n",
       "leven                                             0.612613\n",
       "Name: 143101, dtype: object"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "metric-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А как я могу доверять тебе\n",
      "Откуда мне знать что я могу верить вам\n"
     ]
    }
   ],
   "source": [
    "q = df.sample(3).iloc[0]\n",
    "\n",
    "print(q['text1'])\n",
    "print(q['text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "emerging-magazine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176747/176747 [00:12<00:00, 13685.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "\n",
    "for _, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    c.update(Counter(row['text1']))\n",
    "    c.update(Counter(row['text2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "developmental-intro",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "garbage = set(['ї',\n",
    " '„',\n",
    " 'Ђ',\n",
    " 'Ќ',\n",
    " '\\\\',\n",
    " '”',\n",
    " '#',\n",
    " 'j',\n",
    " '•',\n",
    " 'ќ',\n",
    " 'Є',\n",
    " 'q',\n",
    " 'ћ',\n",
    " '°',\n",
    " '…',\n",
    " 'Ь',\n",
    " '§',\n",
    " '·',\n",
    " '@',\n",
    " 'ƒ',\n",
    " '®',\n",
    " '—',\n",
    " '}',\n",
    " '’',\n",
    " 'Ѕ',\n",
    " 'Ћ',\n",
    " '~',\n",
    " '►',\n",
    " '\\xad',\n",
    " '^',\n",
    " 'Η',\n",
    " '™',\n",
    " '●',\n",
    " 'ä',\n",
    " '`',\n",
    " 'І',\n",
    " '×',\n",
    " 'ѣ',\n",
    " 'ο',\n",
    " 'є',\n",
    " '‘',\n",
    " '±',\n",
    " '{',\n",
    " '・',\n",
    " 'ń',\n",
    " '◈',\n",
    " '▶',\n",
    " 'á',\n",
    " 'ü',\n",
    " '\\x07',\n",
    " 'ā',\n",
    " '½',\n",
    " 'ѐ',\n",
    " '◊',\n",
    " '−',\n",
    " '\\x1f',\n",
    " 'ö',\n",
    " 'Π',\n",
    " '£',\n",
    " 'º',\n",
    " 'Џ',\n",
    " 'ό',\n",
    " '═',\n",
    " '¬',\n",
    " '\\u200e',\n",
    " '╣',\n",
    " '╚',\n",
    " '╩',\n",
    " '└',\n",
    " '\\ufeff',\n",
    " '‐',\n",
    " '─',\n",
    " 'β',\n",
    " '→',\n",
    " 'Τ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "dental-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'§|◊|}|\\\\|◈|~|™|á|ü|\\u200e|・|ń|‘|ο|ā|\\x1f|{|Η|└|▶|°|®|^|\\ufeff|ї|…|І|Π|£|\\x07|‐|„|j|”|►|╩|Τ|`|Ѕ|Ь|q|Є|ѣ|є|●|½|→|×|Ќ|·|\\xad|ό|╚|ћ|╣|ƒ|Ћ|═|ќ|−|ö|β|º|±|’|—|Џ|Ђ|#|ä|ѐ|─|@|¬|•'"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'.join(garbage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "passive-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_garbage(s):\n",
    "    s = set(s)\n",
    "    for el in garbage:\n",
    "        if el in s:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "reported-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text1.apply(has_garbage)]\n",
    "df = df[~df.text2.apply(has_garbage)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "nearby-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/clean/rysshe_clean.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "atomic-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>ent1</th>\n",
       "      <th>ent2</th>\n",
       "      <th>leven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>news</td>\n",
       "      <td>Трамп рассказал о ситуации с коронавирусом в США</td>\n",
       "      <td>Трамп оценил ситуацию с коронавирусом в США</td>\n",
       "      <td>0.842401</td>\n",
       "      <td>0.859896</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>news</td>\n",
       "      <td>В Иране коронавирусом заразился высокопоставле...</td>\n",
       "      <td>В Иране чиновник заболел коронавирусом</td>\n",
       "      <td>0.969853</td>\n",
       "      <td>0.771793</td>\n",
       "      <td>0.432990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>news</td>\n",
       "      <td>Иранский министр заразился коронавирусом</td>\n",
       "      <td>Высокопоставленный иранский чиновник заразился...</td>\n",
       "      <td>0.893407</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>news</td>\n",
       "      <td>У замминистра здравоохранения Ирана выявили ко...</td>\n",
       "      <td>Коронавирус поразил замминистра здравоохранени...</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>0.842087</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>news</td>\n",
       "      <td>Замминистра здравоохранения Ирана заразился ко...</td>\n",
       "      <td>Коронавирус поразил замминистра здравоохранени...</td>\n",
       "      <td>0.989599</td>\n",
       "      <td>0.901100</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098363</th>\n",
       "      <td>subs</td>\n",
       "      <td>С ней всё будет в порядке</td>\n",
       "      <td>С тобой все будет хорошо</td>\n",
       "      <td>0.949547</td>\n",
       "      <td>0.971785</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098364</th>\n",
       "      <td>subs</td>\n",
       "      <td>С ней всё в порядке</td>\n",
       "      <td>С тобой все в порядке</td>\n",
       "      <td>0.943584</td>\n",
       "      <td>0.966565</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098366</th>\n",
       "      <td>subs</td>\n",
       "      <td>Нет дело не в этом</td>\n",
       "      <td>Я не это имел в виду</td>\n",
       "      <td>0.825783</td>\n",
       "      <td>0.871824</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098384</th>\n",
       "      <td>subs</td>\n",
       "      <td>Что ты об этом думаешь</td>\n",
       "      <td>Что ты хочешь этим сказать</td>\n",
       "      <td>0.791357</td>\n",
       "      <td>0.848458</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098385</th>\n",
       "      <td>subs</td>\n",
       "      <td>Нет я так не думаю</td>\n",
       "      <td>Я бы так не сказал</td>\n",
       "      <td>0.797928</td>\n",
       "      <td>0.787972</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175896 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kind                                              text1  \\\n",
       "230      news   Трамп рассказал о ситуации с коронавирусом в США   \n",
       "248      news  В Иране коронавирусом заразился высокопоставле...   \n",
       "255      news           Иранский министр заразился коронавирусом   \n",
       "279      news  У замминистра здравоохранения Ирана выявили ко...   \n",
       "297      news  Замминистра здравоохранения Ирана заразился ко...   \n",
       "...       ...                                                ...   \n",
       "3098363  subs                          С ней всё будет в порядке   \n",
       "3098364  subs                                С ней всё в порядке   \n",
       "3098366  subs                                 Нет дело не в этом   \n",
       "3098384  subs                             Что ты об этом думаешь   \n",
       "3098385  subs                                 Нет я так не думаю   \n",
       "\n",
       "                                                     text2      ent1  \\\n",
       "230            Трамп оценил ситуацию с коронавирусом в США  0.842401   \n",
       "248                 В Иране чиновник заболел коронавирусом  0.969853   \n",
       "255      Высокопоставленный иранский чиновник заразился...  0.893407   \n",
       "279      Коронавирус поразил замминистра здравоохранени...  0.854719   \n",
       "297      Коронавирус поразил замминистра здравоохранени...  0.989599   \n",
       "...                                                    ...       ...   \n",
       "3098363                           С тобой все будет хорошо  0.949547   \n",
       "3098364                              С тобой все в порядке  0.943584   \n",
       "3098366                               Я не это имел в виду  0.825783   \n",
       "3098384                         Что ты хочешь этим сказать  0.791357   \n",
       "3098385                                 Я бы так не сказал  0.797928   \n",
       "\n",
       "             ent2     leven  \n",
       "230      0.859896  0.813187  \n",
       "248      0.771793  0.432990  \n",
       "255      0.867574  0.700000  \n",
       "279      0.842087  0.629630  \n",
       "297      0.901100  0.581818  \n",
       "...           ...       ...  \n",
       "3098363  0.971785  0.612245  \n",
       "3098364  0.966565  0.800000  \n",
       "3098366  0.871824  0.421053  \n",
       "3098384  0.848458  0.625000  \n",
       "3098385  0.787972  0.555556  \n",
       "\n",
       "[175896 rows x 6 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-clinic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
